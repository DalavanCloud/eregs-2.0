{
    "docs": [
        {
            "location": "/", 
            "text": "eRegs 2.0\n\n\nThis is the documentation for the new version of \neRegs\n, the interface for reading the Bureau's regulatory documents. This document describes how to deploy eRegs, add and update content, and troubleshoot.\n\n\nGetting eRegs\n\n\neRegs can be checked out from the Github repository:\n\n\ngit clone https://github.com/cfpb/eregs-2.0\ncd eregs-2.0\npip install -r requirements.txt\n\n\n\nThe other thing you'll need is the \neregsip\n repository, which contains some static content for branding. If you are inside the CFPB developer VPN, you know where you can find this repository, and if you're not, you'll have to go without. You can run the project without this repository, but some static assets will be missing.\n\n\nInstalling the prerequisites\n\n\nIn addition to installing the various required Python modules, you will need to install and configure a MySQL database and an ElasticSearch instance. If you are developing on a Mac, you may be able to install both of these via \nhomebrew\n like so:\n\n\nbrew install mysql\nbrew install elasticsearch23\n\n\n\nNote that you will need ElasticSearch 2.3, not one of the later versions, which do not work correctly with Haystack, the search interface between Django and a search backend. If you are not able to install ElasticSearch 2.3, it might have been removed from Homebrew, in which case you will have to download the binary yourself. You can get the ElasticSearch 2.3 binar \nhere\n.\n\n\nOnce you have MySQL installed, you'll need to configure it to match the \nsettings.py\n file. This means creating the two databases, creating the appropriate users, and granting those users privileges on the databases. First, create two databases named \neregs\n and \ntest_eregs\n. Then, create the user \neregs\n authenticated by the password \neregs\n. Finally, grant the \neregs\n user privileges by logging into MySQL as root (\nmysql -u root\n) and running the following commands:\n\n\ngrant all privileges on eregs.* to 'eregs'@'localhost' identified by eregs\ngrant all privileges on eregs.* to 'test_eregs'@'localhost' identified by eregs\n\n\n\nOnce that's done, you should run \n./manage.py migrate\n to create the database and the model tables. You should also make sure that ElasticSearch is running.\n\n\nLoading data\n\n\nIn order to load data, you'll need to grab the repository that contains the RegML files. Wherever you want to have this data, do:\n\n\ngit clone https://github.com/cfpb/regulations-xml\n\n\n\nThis repository has the following structure:\n\n\nimages                     # images that are embedded in the regulations\nnotice/                    # change notices for each regulation\n    1003/                  # reg C\n        2012-31311.xml\n        ...                # etc.\n    1005/                  # reg E\n        2012-01728.xml\n        ...                # etc.\n    ...                    # etc.\nregulation/                # compiled regulations\n    1003/                  # reg C\n        2011-31712.xml     # initial version of the regulation\n        2012-31311.xml     # result of applying first notice\n        ...                # etc.\n    ...                    # etc.\n\n\n\nIf you run \n./manage.py runserver\n and go to \nlocalhost:8000\n, you'll see that there is no content in eRegs. To load some content, run the following management command:\n\n\n./manage.py import_xml /path/to/regulations-xml/regulation/1003/2011-31712.xml\n\n\n\nThis will import the initial version of Regulation C into eRegs. If you refresh your view, you will now see Regulation C on the landing page. You should be able to navigate the regulation interface in the same way that you navigate the current production eRegs interface.\n\n\nIn order to get search to work, you'll need to build the index:\n\n\n./manage.py rebuild_index\n\n\n\nThis will build the ElasticSearch index for eRegs. In the future, you can update the index by running \n./manage.py update_index\n. You should now be able to search the eRegs regulatory text in the normal manner.\n\n\nLoading diffs\n\n\nDiffs are a special form of content that indicate the difference between two versions of a regulation. It is important to note that diffs are \nnot\n symmetric; in other words, if \nX\n and \nY\n are versions of a single regulation, \ndiff(X, Y) != diff(Y, X)\n. Therefore, right now, if you want to display bidirectional differences in regulatory content, you need to generate diffs in both directions. There's a command to do that:\n\n\n./manage.py import_diff /path/to/regulations-xml/regulation/regnumber/version1.xml /path/to/regulations-xml/regulation/regnumber/version2.xml\n./manage.py import_diff /path/to/regulations-xml/regulation/regnumber/version2.xml /path/to/regulations-xml/regulation/regnumber/version1.xml\n\n\n\nHere, \nregnumber\n is the part number of the regulation (e.g. 1003) and \nversion1\n and \nversion2\n are the document numbers of the respective versions. Make sure that \nregnumber\n is the same in both cases; you can of course generate a diff between two different part numbers, but that diff would make no sense. In the future, there will be a single management command that will generate the bidirectional diffs for you, but for the moment, you have to run it twice with the arguments swapped, as above, to have differences in both directions.", 
            "title": "Installation and Data Loading"
        }, 
        {
            "location": "/#eregs-20", 
            "text": "This is the documentation for the new version of  eRegs , the interface for reading the Bureau's regulatory documents. This document describes how to deploy eRegs, add and update content, and troubleshoot.", 
            "title": "eRegs 2.0"
        }, 
        {
            "location": "/#getting-eregs", 
            "text": "eRegs can be checked out from the Github repository:  git clone https://github.com/cfpb/eregs-2.0\ncd eregs-2.0\npip install -r requirements.txt  The other thing you'll need is the  eregsip  repository, which contains some static content for branding. If you are inside the CFPB developer VPN, you know where you can find this repository, and if you're not, you'll have to go without. You can run the project without this repository, but some static assets will be missing.", 
            "title": "Getting eRegs"
        }, 
        {
            "location": "/#installing-the-prerequisites", 
            "text": "In addition to installing the various required Python modules, you will need to install and configure a MySQL database and an ElasticSearch instance. If you are developing on a Mac, you may be able to install both of these via  homebrew  like so:  brew install mysql\nbrew install elasticsearch23  Note that you will need ElasticSearch 2.3, not one of the later versions, which do not work correctly with Haystack, the search interface between Django and a search backend. If you are not able to install ElasticSearch 2.3, it might have been removed from Homebrew, in which case you will have to download the binary yourself. You can get the ElasticSearch 2.3 binar  here .  Once you have MySQL installed, you'll need to configure it to match the  settings.py  file. This means creating the two databases, creating the appropriate users, and granting those users privileges on the databases. First, create two databases named  eregs  and  test_eregs . Then, create the user  eregs  authenticated by the password  eregs . Finally, grant the  eregs  user privileges by logging into MySQL as root ( mysql -u root ) and running the following commands:  grant all privileges on eregs.* to 'eregs'@'localhost' identified by eregs\ngrant all privileges on eregs.* to 'test_eregs'@'localhost' identified by eregs  Once that's done, you should run  ./manage.py migrate  to create the database and the model tables. You should also make sure that ElasticSearch is running.", 
            "title": "Installing the prerequisites"
        }, 
        {
            "location": "/#loading-data", 
            "text": "In order to load data, you'll need to grab the repository that contains the RegML files. Wherever you want to have this data, do:  git clone https://github.com/cfpb/regulations-xml  This repository has the following structure:  images                     # images that are embedded in the regulations\nnotice/                    # change notices for each regulation\n    1003/                  # reg C\n        2012-31311.xml\n        ...                # etc.\n    1005/                  # reg E\n        2012-01728.xml\n        ...                # etc.\n    ...                    # etc.\nregulation/                # compiled regulations\n    1003/                  # reg C\n        2011-31712.xml     # initial version of the regulation\n        2012-31311.xml     # result of applying first notice\n        ...                # etc.\n    ...                    # etc.  If you run  ./manage.py runserver  and go to  localhost:8000 , you'll see that there is no content in eRegs. To load some content, run the following management command:  ./manage.py import_xml /path/to/regulations-xml/regulation/1003/2011-31712.xml  This will import the initial version of Regulation C into eRegs. If you refresh your view, you will now see Regulation C on the landing page. You should be able to navigate the regulation interface in the same way that you navigate the current production eRegs interface.  In order to get search to work, you'll need to build the index:  ./manage.py rebuild_index  This will build the ElasticSearch index for eRegs. In the future, you can update the index by running  ./manage.py update_index . You should now be able to search the eRegs regulatory text in the normal manner.", 
            "title": "Loading data"
        }, 
        {
            "location": "/#loading-diffs", 
            "text": "Diffs are a special form of content that indicate the difference between two versions of a regulation. It is important to note that diffs are  not  symmetric; in other words, if  X  and  Y  are versions of a single regulation,  diff(X, Y) != diff(Y, X) . Therefore, right now, if you want to display bidirectional differences in regulatory content, you need to generate diffs in both directions. There's a command to do that:  ./manage.py import_diff /path/to/regulations-xml/regulation/regnumber/version1.xml /path/to/regulations-xml/regulation/regnumber/version2.xml\n./manage.py import_diff /path/to/regulations-xml/regulation/regnumber/version2.xml /path/to/regulations-xml/regulation/regnumber/version1.xml  Here,  regnumber  is the part number of the regulation (e.g. 1003) and  version1  and  version2  are the document numbers of the respective versions. Make sure that  regnumber  is the same in both cases; you can of course generate a diff between two different part numbers, but that diff would make no sense. In the future, there will be a single management command that will generate the bidirectional diffs for you, but for the moment, you have to run it twice with the arguments swapped, as above, to have differences in both directions.", 
            "title": "Loading diffs"
        }, 
        {
            "location": "/regml/", 
            "text": "Logic, motivation, and use\n\n\nThis part of the documentation explains the motivation for switching to an XML format and the way in which this change simplifies the process of adding content into eRegs.\n\n\nregulations-parser\n\n\nThe process of creating the content that powers eRegs begins with a Python program called \nregulations-parser\n. The parser takes as its input the raw XML from the Federal Register. In the past, the parser would generate the JSON layers described in the \nAPI\n section, and they would be stored in the database as indicated on the diagram. Now, the parser generates a set of XML files; the first of these files represents the document that originates the regulation (e.g. \n2011-31712.xml\n for the original document of Regulation C), and the subsequent XML documents represent notices that modify the \nprevious\n version of the regulation. Thus, if \n2011-31712\n is the original version, and \n2012-31311\n is the notice representing the chronologically next modification, then \"applying\" the \nnotice\n \n2011-31311\n to the \nregulation\n \n2011-31712\n generates the \nnew reguation\n \n2011-31311\n. The \nnext\n notice will then modify the regulation \n2011-31311\n, and so on.\n\n\nThe benefit of this structure is that fixes that are made upstream propagate downstread. In the old pipeline, modifying the individual JSON files was too complicated, so any changes had to be made to the source Federal Register XML and the entire parser needed to be run again. This made the process of compiling regulations hopelessly opaque and slow, especially for larger regulations like Z. With the introduction of RegML, initial mistakes in compilation can be fixed in the root version, and then incremental fixes can be made in the notices, which are typically much smaller than a fully compiled regulation. Once you have fixed version \nN\n and notice \nN+1\n, version \nN+1\n which is obtained by applying notice \nN+1\n to version \nN\n, will maintain those fixes. This makes it possible to incrementally fix mistakes in regulation compilation.\n\n\nAdditionally, fixing an XML file that can be validated with a schema is much easier than fixing the typically malformed, non-semantic XML that the Federal Register provides. RegML was designed with the goal of capturing the entire semantics of a regulation, whereas the Federal Register XML is designed to be compiled to a printable PDF. In particular, RegML is designed to have a 1-1 correspondence between XML node and Django database model, as well as with the goal of separating visual representation from semantic markup. Thus, fixing errors in a RegML file requires substantially less time and effort.\n\n\nThe logic of RegML\n\n\nRegML is designed to capture regulation semantics, separate model structure from presentation, and maintain an isomorphism between XML node and database row. You can find \nthe schema for RegML\n on Github. The schema is amply documented and should be mostly self-explanatory; it captures both the structure of a regulatory document in the form of a hierarchy of nodes, and the semantics of the text that indicate linkages between different parts of the regulation, such as definitions and references.\n\n\nPowering eRegs 2.0\n\n\nAs documented in the \nAPI\n section and the \nintroduction\n, the new eRegs backend replaces the Byzantine collection of JSON layers with a storage logic based on nested sets. Now, instead of breaking the RegML file into layers and then reassembling them on the site backend, the entire RegML tree can just be imported directly into the database. This eliminates the necessity of uploading large files (an update to Regulation Z can be as much as ~10Gb), and makes it much easier to store the canonical representation of a regulation in a repository. This also aids automation, as it is possible to automatically pull down an updated production branch of a repository and insert it into the database without the need of passing through multiple pipeline stages.", 
            "title": "RegML"
        }, 
        {
            "location": "/regml/#logic-motivation-and-use", 
            "text": "This part of the documentation explains the motivation for switching to an XML format and the way in which this change simplifies the process of adding content into eRegs.", 
            "title": "Logic, motivation, and use"
        }, 
        {
            "location": "/regml/#regulations-parser", 
            "text": "The process of creating the content that powers eRegs begins with a Python program called  regulations-parser . The parser takes as its input the raw XML from the Federal Register. In the past, the parser would generate the JSON layers described in the  API  section, and they would be stored in the database as indicated on the diagram. Now, the parser generates a set of XML files; the first of these files represents the document that originates the regulation (e.g.  2011-31712.xml  for the original document of Regulation C), and the subsequent XML documents represent notices that modify the  previous  version of the regulation. Thus, if  2011-31712  is the original version, and  2012-31311  is the notice representing the chronologically next modification, then \"applying\" the  notice   2011-31311  to the  regulation   2011-31712  generates the  new reguation   2011-31311 . The  next  notice will then modify the regulation  2011-31311 , and so on.  The benefit of this structure is that fixes that are made upstream propagate downstread. In the old pipeline, modifying the individual JSON files was too complicated, so any changes had to be made to the source Federal Register XML and the entire parser needed to be run again. This made the process of compiling regulations hopelessly opaque and slow, especially for larger regulations like Z. With the introduction of RegML, initial mistakes in compilation can be fixed in the root version, and then incremental fixes can be made in the notices, which are typically much smaller than a fully compiled regulation. Once you have fixed version  N  and notice  N+1 , version  N+1  which is obtained by applying notice  N+1  to version  N , will maintain those fixes. This makes it possible to incrementally fix mistakes in regulation compilation.  Additionally, fixing an XML file that can be validated with a schema is much easier than fixing the typically malformed, non-semantic XML that the Federal Register provides. RegML was designed with the goal of capturing the entire semantics of a regulation, whereas the Federal Register XML is designed to be compiled to a printable PDF. In particular, RegML is designed to have a 1-1 correspondence between XML node and Django database model, as well as with the goal of separating visual representation from semantic markup. Thus, fixing errors in a RegML file requires substantially less time and effort.", 
            "title": "regulations-parser"
        }, 
        {
            "location": "/regml/#the-logic-of-regml", 
            "text": "RegML is designed to capture regulation semantics, separate model structure from presentation, and maintain an isomorphism between XML node and database row. You can find  the schema for RegML  on Github. The schema is amply documented and should be mostly self-explanatory; it captures both the structure of a regulatory document in the form of a hierarchy of nodes, and the semantics of the text that indicate linkages between different parts of the regulation, such as definitions and references.", 
            "title": "The logic of RegML"
        }, 
        {
            "location": "/regml/#powering-eregs-20", 
            "text": "As documented in the  API  section and the  introduction , the new eRegs backend replaces the Byzantine collection of JSON layers with a storage logic based on nested sets. Now, instead of breaking the RegML file into layers and then reassembling them on the site backend, the entire RegML tree can just be imported directly into the database. This eliminates the necessity of uploading large files (an update to Regulation Z can be as much as ~10Gb), and makes it much easier to store the canonical representation of a regulation in a repository. This also aids automation, as it is possible to automatically pull down an updated production branch of a repository and insert it into the database without the need of passing through multiple pipeline stages.", 
            "title": "Powering eRegs 2.0"
        }, 
        {
            "location": "/api/", 
            "text": "eRegs API - a guided tour\n\n\nThis part of the documentation provides an explanation of the eRegs API and the design, storage, and view logic of the project.\n\n\nDifferences from old eRegs\n\n\nThe eRegs API is drastically revised from the previous version. Before the advent of eRegs 2.0, the eRegs deployment process involved breaking a regulation up into its constituent parts, storing those parts in the database as \"layers\", and then reassembling those layers into the final display version of the regulation. The diagram below illustrates the old eRegs content generation process:\n\n\n\n\nNot only was this process complicated and error-prone (in particular, the assembly of layers into the display HTML could fail in unexpected ways if some crucial piece of content was missing from the JSON layers), but it also took an extremely long time, especially for giant regulations like Z. Furthermore, because of the original design of eRegs, the storage logic actually lived in a different project called \nregcore\n which provided an API to \nregsite\n, which was the actual project that fetched the data and displayed it.\n\n\nIn the new version of eRegs, all of this complexity has been eliminated. The new eRegs stores the regulation tree directly in a single table and designates a node's position in the regulation tree hierarchy through the use of \nnested sets\n. The \nregcore\n project is eliminated entirely and display HTML is generated directly via server-side templating. The result is the following conceptual diagram, encompassed by a single project:\n\n\n\n\nURL scheme\n\n\nThe old eRegs API contained a complicated URL scheme which required a great deal of complicated server-side processing in order to render the appropriate content. The new API simplifies the URL scheme using the principle that there are three pieces of data that uniquely identify a node within the regulatory structure: the document number, the effective date, and the node label. Althought not every node in the tree has a label, every node \neither\n has a label \nor\n is uniquely associated with a labeled node (in principle, every node \ncould\n have a label, if it is so desired), and any node \nthat can be navigated to\n has a label.\n\n\nThe document number identifies the actual document, as issued by the Federal Register, in which the content originates. For example, the initial document that originates Regulation C has the document number \n2011-31712\n. A document contains at least one, but possibly more effective dates, which indicate on which date the regulatory text becomes effective. An example of this is a document that amends Regulation C, \n2015-26607\n, which contains \nthree\n effective dates (1/1/2017, 1/1/2018, and 1/1/2019). Obviously, multiple regulations may become effective on the same date.\n\n\nThe label of a node uniquely identifies the node \nwithin that specific regulation tree\n. With a few exceptions, the label consists of the part number, either the section number or the appendix letter, and the paragraph marker(s), separated by dashes. For example, Section 1 in Regulation C will have the label \n1003-1\n, the first paragraph in that section has label \n1003-1-a\n and so on. Nodes for interpretations have the form of the node to which they are appended, followed by the word \nInterp\n, and then followed by paragraph markers indicating the internal structure of the interpretation paragraph or section. So, for example, the interpretation of paragraph (a)(1) of section 3 will have the label \n1003-3-a-1-Interp\n, and its first paragraph would have the label \n1003-3-a-1-Interp-1\n, and so on.\n\n\nTogether, the document number, the effective date, and the label, separated by colons, are combined into a uniquely identifying \nnode_id\n. Thus, paragraph (a) of section 1 of Regulation C from the document \n2011-31712\n effective on \n2011-12-30\n will have the \nnode_id\n of \n2011-31712:2011-12-30:1003-1-a\n. Accoringly, that node (or any other node with a label) can be accessed via the url \nlocalhost:8000/regulation/2011-31712/2011-12-30/1003-1-a\n.\n\n\nModel logic\n\n\nThe entire storage logic of the new eRegs is rooted in a single model, \nRegNode\n. That model defines the basic properties of a node (\nlabel\n, \ntext\n, \ntag\n, \nnode_id\n). It also defines a \nversion\n property, which is the document number and effective date concatenated together with a colon, e.g. \n2011-31712:2011-12-30\n. There is also an \nattribs\n property which is a \nJSONField\n (present only in MySQL 5.7+ and PostgreSQL 9.3+). The \nattribs\n field contains all the data that would be present as an attribute in the RegML, e.g. \nparagraph marker=(a)\n would generate a \nRegNode\n whose \nattribs\n dictionary would contain a \nmarker\n key whose value is \n(a)\n. The \nRegNode\n inherits some generic node functions for fetching descendants and ancestors of an element in a nested set (\nGenericNodeMixin\n) and provides some additional functionality for testing the type of internal list that the node contains, if any, and which of its children have content, if any.\n\n\nSubsequent node types are derived from \nRegNode\n as proxy models, which means that they do not have their own table; they are simply extensions of the \nRegNode\n that provide additional functionality. So, for example, the \nParagraph\n model contains additional functionality for displaying the paragraphs, and so on. There is a one-to-one correspondence between the \ntag\n of a node (as obtained from the RegML), which allows automatic inference of node class when retrieving descendants and ancestors.\n\n\nThe only special node that is derived from \nRegNode\n is the \nDiffNode\n, which \ndoes\n have its own table. The difference between \nRegNode\n and \nDiffNode\n is that the \nDiffNode\n contains \ntwo\n version fields, \nleft_version\n and \nright_version\n, which carry the same semantics as the \nversion\n field of \nRegNode\n. Thus, every \nDiffNode\n in the table encodes the difference between the left and right versions of the regulation. As noted in the \ninstallation\n guide, diffs are \nnot\n symmetric; thus a \nDiffNode\n with \nleft version = X\n and \nright_version = Y\n is not necessarily identical to one with \nleft_version = Y\n and \nright_version = X\n. Additionally, all node models which can encode version-differing content have accessory functions for retrieving the left and right versions of the content, as well as for rendering it.\n\n\nView logic\n\n\nThe view logic in eRegs 2.0 is also drastically simplified relative to the old version of eRegs. The basic structure of a view is that it's identified by its functionality prepended to the aforementioned URL scheme, so that e.g. a node within a regulation has the relative URL \nregulation/2011-31712/2011-12-30/1003-1-a\n. Most of the other views are intended to render partials, and thus the URL is prepended with e.g. \npartial/sxs/\n or \npartial/definition/\n. Views that render partials return the appropriate HTML directly to the caller, which can then be appended in the correct place on the front-end.\n\n\nTemplate logic\n\n\nThe major templating work happens in the \nregnode.html\n file. The basic logic of that file is to render the regulation tree, starting at the specified root node, in a recursive fashion. Thus, depending on the type of node, \nregnode.html\n renders the opening HTML tag, recurses into the node to render its insides, and then renders the closing HTML tag on the way back up. There are some templates that render content independent of this structure (for example the sidebar, analysis, and table of contents are rendered separately). This simplifies the process of the old eRegs, in which the various JSON layers were assembled into the final rendered HTML; instead, there is a single point of entry for most rendering and substantially fewer places where an exception could happen.", 
            "title": "API"
        }, 
        {
            "location": "/api/#eregs-api-a-guided-tour", 
            "text": "This part of the documentation provides an explanation of the eRegs API and the design, storage, and view logic of the project.", 
            "title": "eRegs API - a guided tour"
        }, 
        {
            "location": "/api/#differences-from-old-eregs", 
            "text": "The eRegs API is drastically revised from the previous version. Before the advent of eRegs 2.0, the eRegs deployment process involved breaking a regulation up into its constituent parts, storing those parts in the database as \"layers\", and then reassembling those layers into the final display version of the regulation. The diagram below illustrates the old eRegs content generation process:   Not only was this process complicated and error-prone (in particular, the assembly of layers into the display HTML could fail in unexpected ways if some crucial piece of content was missing from the JSON layers), but it also took an extremely long time, especially for giant regulations like Z. Furthermore, because of the original design of eRegs, the storage logic actually lived in a different project called  regcore  which provided an API to  regsite , which was the actual project that fetched the data and displayed it.  In the new version of eRegs, all of this complexity has been eliminated. The new eRegs stores the regulation tree directly in a single table and designates a node's position in the regulation tree hierarchy through the use of  nested sets . The  regcore  project is eliminated entirely and display HTML is generated directly via server-side templating. The result is the following conceptual diagram, encompassed by a single project:", 
            "title": "Differences from old eRegs"
        }, 
        {
            "location": "/api/#url-scheme", 
            "text": "The old eRegs API contained a complicated URL scheme which required a great deal of complicated server-side processing in order to render the appropriate content. The new API simplifies the URL scheme using the principle that there are three pieces of data that uniquely identify a node within the regulatory structure: the document number, the effective date, and the node label. Althought not every node in the tree has a label, every node  either  has a label  or  is uniquely associated with a labeled node (in principle, every node  could  have a label, if it is so desired), and any node  that can be navigated to  has a label.  The document number identifies the actual document, as issued by the Federal Register, in which the content originates. For example, the initial document that originates Regulation C has the document number  2011-31712 . A document contains at least one, but possibly more effective dates, which indicate on which date the regulatory text becomes effective. An example of this is a document that amends Regulation C,  2015-26607 , which contains  three  effective dates (1/1/2017, 1/1/2018, and 1/1/2019). Obviously, multiple regulations may become effective on the same date.  The label of a node uniquely identifies the node  within that specific regulation tree . With a few exceptions, the label consists of the part number, either the section number or the appendix letter, and the paragraph marker(s), separated by dashes. For example, Section 1 in Regulation C will have the label  1003-1 , the first paragraph in that section has label  1003-1-a  and so on. Nodes for interpretations have the form of the node to which they are appended, followed by the word  Interp , and then followed by paragraph markers indicating the internal structure of the interpretation paragraph or section. So, for example, the interpretation of paragraph (a)(1) of section 3 will have the label  1003-3-a-1-Interp , and its first paragraph would have the label  1003-3-a-1-Interp-1 , and so on.  Together, the document number, the effective date, and the label, separated by colons, are combined into a uniquely identifying  node_id . Thus, paragraph (a) of section 1 of Regulation C from the document  2011-31712  effective on  2011-12-30  will have the  node_id  of  2011-31712:2011-12-30:1003-1-a . Accoringly, that node (or any other node with a label) can be accessed via the url  localhost:8000/regulation/2011-31712/2011-12-30/1003-1-a .", 
            "title": "URL scheme"
        }, 
        {
            "location": "/api/#model-logic", 
            "text": "The entire storage logic of the new eRegs is rooted in a single model,  RegNode . That model defines the basic properties of a node ( label ,  text ,  tag ,  node_id ). It also defines a  version  property, which is the document number and effective date concatenated together with a colon, e.g.  2011-31712:2011-12-30 . There is also an  attribs  property which is a  JSONField  (present only in MySQL 5.7+ and PostgreSQL 9.3+). The  attribs  field contains all the data that would be present as an attribute in the RegML, e.g.  paragraph marker=(a)  would generate a  RegNode  whose  attribs  dictionary would contain a  marker  key whose value is  (a) . The  RegNode  inherits some generic node functions for fetching descendants and ancestors of an element in a nested set ( GenericNodeMixin ) and provides some additional functionality for testing the type of internal list that the node contains, if any, and which of its children have content, if any.  Subsequent node types are derived from  RegNode  as proxy models, which means that they do not have their own table; they are simply extensions of the  RegNode  that provide additional functionality. So, for example, the  Paragraph  model contains additional functionality for displaying the paragraphs, and so on. There is a one-to-one correspondence between the  tag  of a node (as obtained from the RegML), which allows automatic inference of node class when retrieving descendants and ancestors.  The only special node that is derived from  RegNode  is the  DiffNode , which  does  have its own table. The difference between  RegNode  and  DiffNode  is that the  DiffNode  contains  two  version fields,  left_version  and  right_version , which carry the same semantics as the  version  field of  RegNode . Thus, every  DiffNode  in the table encodes the difference between the left and right versions of the regulation. As noted in the  installation  guide, diffs are  not  symmetric; thus a  DiffNode  with  left version = X  and  right_version = Y  is not necessarily identical to one with  left_version = Y  and  right_version = X . Additionally, all node models which can encode version-differing content have accessory functions for retrieving the left and right versions of the content, as well as for rendering it.", 
            "title": "Model logic"
        }, 
        {
            "location": "/api/#view-logic", 
            "text": "The view logic in eRegs 2.0 is also drastically simplified relative to the old version of eRegs. The basic structure of a view is that it's identified by its functionality prepended to the aforementioned URL scheme, so that e.g. a node within a regulation has the relative URL  regulation/2011-31712/2011-12-30/1003-1-a . Most of the other views are intended to render partials, and thus the URL is prepended with e.g.  partial/sxs/  or  partial/definition/ . Views that render partials return the appropriate HTML directly to the caller, which can then be appended in the correct place on the front-end.", 
            "title": "View logic"
        }, 
        {
            "location": "/api/#template-logic", 
            "text": "The major templating work happens in the  regnode.html  file. The basic logic of that file is to render the regulation tree, starting at the specified root node, in a recursive fashion. Thus, depending on the type of node,  regnode.html  renders the opening HTML tag, recurses into the node to render its insides, and then renders the closing HTML tag on the way back up. There are some templates that render content independent of this structure (for example the sidebar, analysis, and table of contents are rendered separately). This simplifies the process of the old eRegs, in which the various JSON layers were assembled into the final rendered HTML; instead, there is a single point of entry for most rendering and substantially fewer places where an exception could happen.", 
            "title": "Template logic"
        }, 
        {
            "location": "/pipeline/", 
            "text": "End-to-end pipeline for content deployment\n\n\nThe following is a set of instructions for how to go from a document located on the \nFederal Register\n website to eRegs content.\n\n\nVersioning regulations\n\n\nRegulations are promulgated via notices published by the Federal Register. Every regulation or modification thereof is contained in a specific document number. Document numbers are typically formed by the pattern \nyear\n-\norder-of-publication\n, where \norder-of-publication\n represents the number of the document published that year, i.e. the first document published in 2011 would have the document number 2011-1. Another example: the first notice that originates Regulation C is \n2011-31712\n.\n\n\nRegulations also take effect on particular dates. A single document might contain multiple effective dates, and multiple documents may take effect on the same effective date. The combination of document number and effective date are unique, however, so together they serve to identify a particular version of the regulation. Notices other than the one that originates the regulation will contain modifications to the previous version of the regulation, so the task at hand is to compile the text into an original starting point, plus a series of changes that define the regulation at each step.\n\n\nParsing the original document\n\n\nThe documents that exist on the Federal Register's website are in \"XML\", where the scare quotes indicate that the markup is not semantic, as it is meant to be transpiled into a PDF suitable for printing. What we do is we take that XML and we turn it into a semantic document in which different parts of the regulation are clearly delineated. We also decouple the semantics of the document from its presentation.\n\n\nIn order to make this happen, we rely on a tool called \nregulations-parser\n, which can be found \non Github\n. This tool will fetch the source files, including change notices, from the Federal Register and compiles them into a series of XML files which represent the regulation at every stage of its existence.\n\n\nThe usage of \nregulations-parser\n is described in the README on Github. For the purposes of this walkthrough, we'll assume that you've got the source files to work with. To compile a source file into RegML, run\n\n\npython build_from.py fr-notices/articles/xml/201/131/725.xml 12 2011-31712 15 1693\n\n\n\nThe only really important parameter here is the document number. The other parameters can be left constant (they correspond to the title of the regulation, which is always 12, and the issuing authority, which is actually irrelevant). If all goes well, the parser will figure out which document numbers form the version chain, parse the original document, then fetch and parse the subsequent notices, and finally output the whole thing in XML that validates with the RegML schema. If all does not go well, you might want to read \nthe documentation\n for \nregulation-parser\n. The RegML files thus generated will be located whatever the \nsettings.OUTPUT_DIR\n variable is set to. \n\n\nThe RegML schema\n\n\nThe above procedure only needs to be done once. The point of the RegML schema is to make it so that you don't have to keep running the regulations parser over and over again; the parser is quite finicky and slow and often makes mistakes, and fixing the source that leads to the mistakes is difficult. In order to see the effects, you have to then rerun the whole parser again, which can take hours for large regulations with many notices. With RegML, you instead end up with separate versions of the regulation that can be fixed independently of each other; moreover, changes propagate downstream, so fixing version \nn\n and fixing the notice that transforms \nn\n into \nn + 1\n, automatically ensures that version \nn + 1\n will also be correct. More details about the schema can be found \nhere\n and by reading \nthe code\n and \nthe documentation\n.\n\n\nCompiling regulations\n\n\nNow you have a series of regulation files organized in the following fashion:\n\n\nimages                     # images that are embedded in the regulations\nnotice/                    # change notices for each regulation\n    1003/                  # reg C\n        2012-31311.xml\n        ...                # etc.\n    1005/                  # reg E\n        2012-01728.xml\n        ...                # etc.\n    ...                    # etc.\nregulation/                # compiled regulations\n    1003/                  # reg C\n        2011-31712.xml     # initial version of the regulation\n        2012-31311.xml     # result of applying first notice\n        ...                # etc.\n    ...                    # etc.\ndiff/                      # diff files\n    1003/\n\n\n\nHere, as indicated, the file \nregulation/2011-31311.xml\n is the result of applying the file \nnotice/2012-31311.xml\n to the original notice \nregulation/2011-31712.xml\n. How is this done?\n\n\nYou'll be pleased to learn that there's a tool for that. It's called \nregulations-xml-parser\n and like everything, you can get it \non Github\n. Despite the unfortunate similarity in names, \nregulations-xml-parser\n is not so much a parser as a tool for transforming and verifying RegML. The full set of abilities of \nregulations-xml-parser\n is beyond the scope of this document, but the thing that matters the most to us here is that the tool can take a regulation and apply notices to it in successive fashion to generate every version of the regulation. The easiest way to do this is with the \napply-through\n command, like so:\n\n\npython regml.py apply-through \ntitle-number\n \nregulation-number\n\n\n\n\nThe title number is always going to be 12, because that is the title number of the authorizing legislation. The regulation number is 1001 for Regulation A, 1002 for Regulation B, and so on, down to Regulation Z being number 1026. Beyond Regulation Z, letters are doubled up and the numbering continues in sequence, so that Regulation DD is 1030, for example.\n\n\nWhen you execute the above command, you'll see the original notice and the notices that apply to it. You can choose up to which notice to apply, but if you just hit \nEnter\n you can apply all of them. Assuming everything goes well, the tool will generate a series of regulations that live in the \nregulation/\nregulation-number\n directory from above. Those regulation files are the final form which will be inserted into the database as per the instructions in \nLoading Data\n.\n\n\nGenerating diffs\n\n\nAnother thing that the \nregulations-xml-parser\n does is generate the diffs for the regulation. A diff, as the name suggests, shows the difference between two versions of the same regulation; in all respects, a diff is just a RegML file and is inserted into the database in the same way. To generate diffs, run:\n\n\npython regml.py generate-diffs \nregulation-number\n\n\n\n\nThis will produce two XML files for every pair of regulation versions. Since the diffing is not symmetric, the order of diffs matters. The files will be located in the \ndiff/\nregulation-number\n directory in the tree displayed above. Keep in mind that \ngenerate-diffs\n should be run after running \napply-through\n, since it relies solely on the generated regulation files, not the notices.\n\n\nEditing regulations\n\n\nThe edit-update-data load loop is the key functionality offered by RegML and the improved eRegs backend. The basic logic goes like this: if you find a mistake in the way that some regulation is displayed, the first step is to identify at which point the mistake is introduced into the pipeline. For example, if a regulation has 10 versions, and you see a mistake in version 10, it might have been introduced in version 4. Usually the most straightforward way of finding where the mistake occurs is to simply work backwards until you find where the mistake is. Once you have found the the mistake, you need to fix it in the XML. That means editing the appropriate notice file to fix whatever the problem might be. Once the problem is fixed, run \napply-through\n as above to generate the regulation files, and then run \ngenerate-diffs\n to generate diffs between all the versions of the regulation. Eventually, there will be an option to \ngenerate-diffs\n that will allow you to generate diffs only between the specified versions and every other version, but for now \ngenerate-diffs\n will just use every existing regulation version.\n\n\nDeployment to production\n\n\nRight now, any deployment that happens has to be done manually, i.e. all of these commands have to be run by an actual person. In the future, it should be possible to automate this by hooking up a Jenkins job to the \nregulations-xml\n repository, so that committing a new notice automatically triggers the compilation, diffing, and data uploading steps.", 
            "title": "End-to-end pipeline"
        }, 
        {
            "location": "/pipeline/#end-to-end-pipeline-for-content-deployment", 
            "text": "The following is a set of instructions for how to go from a document located on the  Federal Register  website to eRegs content.", 
            "title": "End-to-end pipeline for content deployment"
        }, 
        {
            "location": "/pipeline/#versioning-regulations", 
            "text": "Regulations are promulgated via notices published by the Federal Register. Every regulation or modification thereof is contained in a specific document number. Document numbers are typically formed by the pattern  year - order-of-publication , where  order-of-publication  represents the number of the document published that year, i.e. the first document published in 2011 would have the document number 2011-1. Another example: the first notice that originates Regulation C is  2011-31712 .  Regulations also take effect on particular dates. A single document might contain multiple effective dates, and multiple documents may take effect on the same effective date. The combination of document number and effective date are unique, however, so together they serve to identify a particular version of the regulation. Notices other than the one that originates the regulation will contain modifications to the previous version of the regulation, so the task at hand is to compile the text into an original starting point, plus a series of changes that define the regulation at each step.", 
            "title": "Versioning regulations"
        }, 
        {
            "location": "/pipeline/#parsing-the-original-document", 
            "text": "The documents that exist on the Federal Register's website are in \"XML\", where the scare quotes indicate that the markup is not semantic, as it is meant to be transpiled into a PDF suitable for printing. What we do is we take that XML and we turn it into a semantic document in which different parts of the regulation are clearly delineated. We also decouple the semantics of the document from its presentation.  In order to make this happen, we rely on a tool called  regulations-parser , which can be found  on Github . This tool will fetch the source files, including change notices, from the Federal Register and compiles them into a series of XML files which represent the regulation at every stage of its existence.  The usage of  regulations-parser  is described in the README on Github. For the purposes of this walkthrough, we'll assume that you've got the source files to work with. To compile a source file into RegML, run  python build_from.py fr-notices/articles/xml/201/131/725.xml 12 2011-31712 15 1693  The only really important parameter here is the document number. The other parameters can be left constant (they correspond to the title of the regulation, which is always 12, and the issuing authority, which is actually irrelevant). If all goes well, the parser will figure out which document numbers form the version chain, parse the original document, then fetch and parse the subsequent notices, and finally output the whole thing in XML that validates with the RegML schema. If all does not go well, you might want to read  the documentation  for  regulation-parser . The RegML files thus generated will be located whatever the  settings.OUTPUT_DIR  variable is set to.", 
            "title": "Parsing the original document"
        }, 
        {
            "location": "/pipeline/#the-regml-schema", 
            "text": "The above procedure only needs to be done once. The point of the RegML schema is to make it so that you don't have to keep running the regulations parser over and over again; the parser is quite finicky and slow and often makes mistakes, and fixing the source that leads to the mistakes is difficult. In order to see the effects, you have to then rerun the whole parser again, which can take hours for large regulations with many notices. With RegML, you instead end up with separate versions of the regulation that can be fixed independently of each other; moreover, changes propagate downstream, so fixing version  n  and fixing the notice that transforms  n  into  n + 1 , automatically ensures that version  n + 1  will also be correct. More details about the schema can be found  here  and by reading  the code  and  the documentation .", 
            "title": "The RegML schema"
        }, 
        {
            "location": "/pipeline/#compiling-regulations", 
            "text": "Now you have a series of regulation files organized in the following fashion:  images                     # images that are embedded in the regulations\nnotice/                    # change notices for each regulation\n    1003/                  # reg C\n        2012-31311.xml\n        ...                # etc.\n    1005/                  # reg E\n        2012-01728.xml\n        ...                # etc.\n    ...                    # etc.\nregulation/                # compiled regulations\n    1003/                  # reg C\n        2011-31712.xml     # initial version of the regulation\n        2012-31311.xml     # result of applying first notice\n        ...                # etc.\n    ...                    # etc.\ndiff/                      # diff files\n    1003/  Here, as indicated, the file  regulation/2011-31311.xml  is the result of applying the file  notice/2012-31311.xml  to the original notice  regulation/2011-31712.xml . How is this done?  You'll be pleased to learn that there's a tool for that. It's called  regulations-xml-parser  and like everything, you can get it  on Github . Despite the unfortunate similarity in names,  regulations-xml-parser  is not so much a parser as a tool for transforming and verifying RegML. The full set of abilities of  regulations-xml-parser  is beyond the scope of this document, but the thing that matters the most to us here is that the tool can take a regulation and apply notices to it in successive fashion to generate every version of the regulation. The easiest way to do this is with the  apply-through  command, like so:  python regml.py apply-through  title-number   regulation-number   The title number is always going to be 12, because that is the title number of the authorizing legislation. The regulation number is 1001 for Regulation A, 1002 for Regulation B, and so on, down to Regulation Z being number 1026. Beyond Regulation Z, letters are doubled up and the numbering continues in sequence, so that Regulation DD is 1030, for example.  When you execute the above command, you'll see the original notice and the notices that apply to it. You can choose up to which notice to apply, but if you just hit  Enter  you can apply all of them. Assuming everything goes well, the tool will generate a series of regulations that live in the  regulation/ regulation-number  directory from above. Those regulation files are the final form which will be inserted into the database as per the instructions in  Loading Data .", 
            "title": "Compiling regulations"
        }, 
        {
            "location": "/pipeline/#generating-diffs", 
            "text": "Another thing that the  regulations-xml-parser  does is generate the diffs for the regulation. A diff, as the name suggests, shows the difference between two versions of the same regulation; in all respects, a diff is just a RegML file and is inserted into the database in the same way. To generate diffs, run:  python regml.py generate-diffs  regulation-number   This will produce two XML files for every pair of regulation versions. Since the diffing is not symmetric, the order of diffs matters. The files will be located in the  diff/ regulation-number  directory in the tree displayed above. Keep in mind that  generate-diffs  should be run after running  apply-through , since it relies solely on the generated regulation files, not the notices.", 
            "title": "Generating diffs"
        }, 
        {
            "location": "/pipeline/#editing-regulations", 
            "text": "The edit-update-data load loop is the key functionality offered by RegML and the improved eRegs backend. The basic logic goes like this: if you find a mistake in the way that some regulation is displayed, the first step is to identify at which point the mistake is introduced into the pipeline. For example, if a regulation has 10 versions, and you see a mistake in version 10, it might have been introduced in version 4. Usually the most straightforward way of finding where the mistake occurs is to simply work backwards until you find where the mistake is. Once you have found the the mistake, you need to fix it in the XML. That means editing the appropriate notice file to fix whatever the problem might be. Once the problem is fixed, run  apply-through  as above to generate the regulation files, and then run  generate-diffs  to generate diffs between all the versions of the regulation. Eventually, there will be an option to  generate-diffs  that will allow you to generate diffs only between the specified versions and every other version, but for now  generate-diffs  will just use every existing regulation version.", 
            "title": "Editing regulations"
        }, 
        {
            "location": "/pipeline/#deployment-to-production", 
            "text": "Right now, any deployment that happens has to be done manually, i.e. all of these commands have to be run by an actual person. In the future, it should be possible to automate this by hooking up a Jenkins job to the  regulations-xml  repository, so that committing a new notice automatically triggers the compilation, diffing, and data uploading steps.", 
            "title": "Deployment to production"
        }
    ]
}